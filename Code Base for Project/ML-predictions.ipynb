{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv(\"machinelearning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean.copy()\n",
    "Y = clean['MinorityDriver']\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "X_train = X_train.drop(\"Unnamed: 0\", axis = 1)\n",
    "X_test = X_test.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True)\n",
    "print(\"here\")\n",
    "for train_index, test_index in folds.split(X_train):\n",
    "        current_train_x, current_test_x = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        current_train_y, current_test_y = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        print(\"here\")\n",
    "        total_x = len(current_train_x[current_train_x['MinorityDriver'] == 1])\n",
    "        white_x = current_train_x[current_train_x.MinorityDriver == 0].index\n",
    "        random_white_x = np.random.choice(white_x, total_x, replace = 'False')\n",
    "        total_index_x = current_train_x[current_train_x.MinorityDriver == 1].index\n",
    "        total_both_x = np.concatenate([total_index_x, random_white_x])\n",
    "        current_train_x = current_train_x.loc[total_both_x]\n",
    "        print(\"here\")\n",
    "        current_train_y = current_train_x['MinorityDriver']\n",
    "        current_train_x = current_train_x.drop(\"MinorityDriver\", axis = 1)\n",
    "        current_test_x = current_test_x.drop(\"MinorityDriver\", axis = 1)\n",
    "        current_test_y = current_test_y['MinorityDriver']\n",
    "        print(\"here\")\n",
    "        model = XGBClassifier(objective= 'binary:logistic')\n",
    "        model.fit(current_train_x, current_train_y)\n",
    "        print(\"here\")\n",
    "        y_pred = model.predict(current_test_x)\n",
    "        print(\"here\")\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        average_precision = average_precision_score(current_test_y, predictions)\n",
    "        accuracy = accuracy_score(current_test_y, predictions)\n",
    "        print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "        print('Average precision-recall score: {0:0.2f}'.format(\n",
    "              average_precision))\n",
    "        auc = roc_auc_score(current_test_y, predictions)\n",
    "        f1 = f1_score(current_test_y, predictions)\n",
    "        print(f1)\n",
    "        print(auc)\n",
    "        print('EndResult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.3, max_depth=5,\n",
    " min_child_weight=2, objective= 'binary:logistic', eval_metric = 'error'), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[6,7,8],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.3, max_depth=5,\n",
    " min_child_weight=2, objective= 'binary:logistic'), \n",
    " param_grid = param_test2, scoring='roc_auc', n_jobs = -1, iid=False, cv=3)\n",
    "gsearch2.fit(X_train, y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[2,4,6,8,10,12]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, max_depth=8,\n",
    " min_child_weight=2,  objective= 'binary:logistic'), \n",
    " param_grid = param_test2b, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch2b.fit(X_train,y_train)\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,7)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(max_depth=8,\n",
    " min_child_weight=4, gamma=0, objective= 'binary:logistic'), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'n_estimators':[0,50,100,150,200,250,300,350,400,450,500]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.3, max_depth=8,\n",
    " min_child_weight=4, gamma=0.1, objective= 'binary:logistic'), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4a = {\n",
    " 'n_estimators':[100,110,120,130,140,150]\n",
    "}\n",
    "gsearch4a = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.3, max_depth=8,\n",
    " min_child_weight=4, gamma=0.1, objective= 'binary:logistic'), \n",
    " param_grid = param_test4a, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch4a.fit(X_train,y_train)\n",
    "gsearch4a.grid_scores_, gsearch4a.best_params_, gsearch4a.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4b = {\n",
    " 'n_estimators':[110,111,112,113,114,115,116,117,118,119,120]\n",
    "}\n",
    "gsearch4b = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.3, max_depth=8,\n",
    " min_child_weight=4, gamma=0.1, objective= 'binary:logistic'), \n",
    " param_grid = param_test4b, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch4b.fit(X_train,y_train)\n",
    "gsearch4b.grid_scores_, gsearch4b.best_params_, gsearch4b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.3, n_estimators=117, max_depth=8,\n",
    " min_child_weight=4, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic'), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'subsample':[i/100.0 for i in range(85,100,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(55,70,5)]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.3, n_estimators=117, max_depth=8,\n",
    " min_child_weight=4, gamma=0.1, subsample=0.9, colsample_bytree=0.6,\n",
    " objective= 'binary:logistic'), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch6.fit(X_train, y_train)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.3, n_estimators=117, max_depth=8,\n",
    " min_child_weight=4, gamma=0.1, subsample=0.95, colsample_bytree=0.55,\n",
    " objective= 'binary:logistic'), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch7.fit(X_train, y_train)\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True)\n",
    "print(\"here\")\n",
    "for train_index, test_index in folds.split(X_train):\n",
    "        current_train_x, current_test_x = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        current_train_y, current_test_y = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        print(\"here\")\n",
    "        total_x = len(current_train_x[current_train_x['MinorityDriver'] == 1])\n",
    "        white_x = current_train_x[current_train_x.MinorityDriver == 0].index\n",
    "        random_white_x = np.random.choice(white_x, total_x, replace = 'False')\n",
    "        total_index_x = current_train_x[current_train_x.MinorityDriver == 1].index\n",
    "        total_both_x = np.concatenate([total_index_x, random_white_x])\n",
    "        current_train_x = current_train_x.loc[total_both_x]\n",
    "        print(\"here\")\n",
    "        current_train_y = current_train_x['MinorityDriver']\n",
    "        current_train_x = current_train_x.drop(\"MinorityDriver\", axis = 1)\n",
    "        current_test_x = current_test_x.drop(\"MinorityDriver\", axis = 1)\n",
    "        current_test_y = current_test_y['MinorityDriver']\n",
    "        print(\"here\")\n",
    "        model = XGBClassifier(learning_rate =0.1, \n",
    "                              n_estimators=300, max_depth=8, min_child_weight=4, gamma=0.1, \n",
    "                              subsample=0.95, colsample_bytree=0.55, reg_alpha = 1, objective= 'binary:logistic',\n",
    "                              scale_pos_weight = 1)\n",
    "        model.fit(current_train_x, current_train_y)\n",
    "        print(\"here\")\n",
    "        y_pred = model.predict(current_test_x)\n",
    "        print(\"here\")\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        average_precision = average_precision_score(current_test_y, predictions)\n",
    "        accuracy = accuracy_score(current_test_y, predictions)\n",
    "        print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "        print('Average precision-recall score: {0:0.2f}'.format(\n",
    "              average_precision))\n",
    "        auc = roc_auc_score(current_test_y, predictions)\n",
    "        f1 = f1_score(current_test_y, predictions)\n",
    "        print(f1)\n",
    "        print(auc)\n",
    "        print('EndResult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_x = len(X_train[X_train['MinorityDriver'] == 1])\n",
    "white_x = X_train[X_train.MinorityDriver == 0].index\n",
    "random_white_x = np.random.choice(white_x, total_x, replace = 'False')\n",
    "total_index_x = X_train[X_train.MinorityDriver == 1].index\n",
    "total_both_x = np.concatenate([total_index_x, random_white_x])\n",
    "X_train = X_train.loc[total_both_x]\n",
    "\n",
    "y_train = X_train['MinorityDriver']\n",
    "\n",
    "X_train = X_train.drop(\"MinorityDriver\", axis = 1)\n",
    "X_train = X_train.drop(\"Unnamed: 0\", axis = 1)\n",
    "X_test = X_test.drop(\"MinorityDriver\", axis = 1)\n",
    "X_test = X_test.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(learning_rate =0.3, n_estimators=300, max_depth=8,\n",
    "                      min_child_weight=4, gamma=0.1, subsample=0.95, colsample_bytree=0.55,\n",
    "                      reg_alpha = 1, objective= 'binary:logistic', scale_pos_weight = 1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "average_precision = average_precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(f1)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "xgb.plot_importance(model)\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "plt.savefig('importance.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree\n",
    "plot_tree(model)\n",
    "plt.savefig('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
